SilentCue - Real-Time Sign Language Translator for Deaf and Non-Verbal Individuals
SilentCue is an AI-driven application designed to bridge the communication gap for deaf and non-verbal individuals. It enables real-time American Sign Language (ASL) gesture recognition using computer vision and machine learning, allowing users to form letters, words, and sentences seamlessly. The system also offers gesture training, dynamic word suggestions, system control, and video call integration, enhancing communication and accessibility.

Features
âœ‹ Real-Time Hand Gesture Detection using OpenCV and MediaPipe.

ğŸ§  Intelligent Word Suggestions via NLTK to form meaningful sentences.

âŒ¨ï¸ Letter Case Toggle (Uppercase/Lowercase) for better sentence construction.

ğŸ§© Custom Gesture Training to add personalized signs.

ğŸ“ˆ Dynamic Sentence Formation and Editing Options.

ğŸ–¥ï¸ Interactive Tkinter GUI for an easy-to-use interface.

ğŸ”— Video Call Integration (TokBox) for remote communication.

ğŸ¯ System Action Control (e.g., opening applications, basic automation).

ğŸ“– Gesture Guide Access for learning standard gestures.

Tech Stack
Programming Language: Python 3

Libraries Used:

OpenCV

MediaPipe

scikit-learn

TensorFlow/Keras (for training models)

NLTK (for word suggestion and sentence formation)

Tkinter (for GUI development)
